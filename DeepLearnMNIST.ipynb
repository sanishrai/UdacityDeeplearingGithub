{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepLearnMNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMA9kXV4iA5ISVpvgWd8frJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanishrai/UdacityDeeplearingGithub/blob/master/DeepLearnMNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiFL-NavWsGp"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VkDCfN6W22s"
      },
      "source": [
        "def activation(x):\n",
        "  return 1/(1+torch.exp(-x))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9JY7cFHXFl-"
      },
      "source": [
        "torch.manual_seed(7)\n",
        "features = torch.randn((1,5))\n",
        "weights = torch.rand_like(features)\n",
        "bias=torch.rand(1,1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8oO_VTHX0UU",
        "outputId": "cdae23e6-b9df-4a27-980c-730885bdd196"
      },
      "source": [
        "input = torch.sum(features * weights)+bias # sum the product and add bias\n",
        "output = activation(input) # send it to sigmoid activation function for output\n",
        "# print(output)\n",
        "# print(weights)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.8072]])\n",
            "tensor([[0.2868, 0.2063, 0.4451, 0.3593, 0.7204]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xujx1dRxZTBc",
        "outputId": "8e3f600f-90a1-406e-8c26-41445104e824"
      },
      "source": [
        "weights = weights.view(5,1)#changing the shape of weights same as features for matrix multiplication\n",
        "input = torch.sum(torch.mm(features, weights))+bias # sum the product and add bias\n",
        "output = activation(input) # send it to sigmoid activation function for output\n",
        "# print(output)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.2868],\n",
            "        [0.2063],\n",
            "        [0.4451],\n",
            "        [0.3593],\n",
            "        [0.7204]])\n",
            "tensor([[0.8072]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3m6sKhMkbFet"
      },
      "source": [
        "# **Second example**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUlB587IbILA"
      },
      "source": [
        "torch.manual_seed(7)\n",
        "features = torch.randn((1,3))\n",
        "#hidden layer\n",
        "n_input = features.shape[1]\n",
        "n_hidden=2\n",
        "n_output=1\n",
        "\n",
        "#weights\n",
        "w1 = torch.randn(n_input,n_hidden)\n",
        "w2 = torch.randn(n_hidden,n_output)\n",
        "\n",
        "#bias\n",
        "b1=torch.randn(1,n_hidden)\n",
        "b2=torch.randn(1,n_output)\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQi3JBYIdoRl",
        "outputId": "6b796efc-50d6-448d-b6cb-7677abee53b2"
      },
      "source": [
        "#print(features)\n",
        "#print(w1)\n",
        "h_vector = torch.mm(features,w1)+b1\n",
        "#print(h_vector)\n",
        "h_activated = activation(h_vector)\n",
        "y = activation(torch.mm(h_activated,w2)+b2)\n",
        "print(y)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.3171]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBKJNfVM2bQ2"
      },
      "source": [
        "# MNIST Example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXWWwm9A2gv8"
      },
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import helper\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j8jgCEjJ95iD"
      },
      "source": [
        "from torchvision import datasets, transforms\n",
        "#a transform to normalize data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,),(0.5,)),\n",
        "                                ])\n",
        "#Download the data\n",
        "train = datasets.MNIST('MNIST_data/',download=True,train=True,transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(train, batch_size=64,shuffle=True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wx4mgpu6ABfH"
      },
      "source": [
        "torch.manual_seed(7)\n",
        "\n",
        "#hidden layer\n",
        "n_input = 784\n",
        "n_hidden=256\n",
        "n_output=10\n",
        "\n",
        "#weights\n",
        "w1 = torch.randn(n_input,n_hidden)\n",
        "w2 = torch.randn(n_hidden,n_output)\n",
        "\n",
        "#bias\n",
        "b1=torch.randn(1,n_hidden)\n",
        "b2=torch.randn(1,n_output)\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFB2pla5A2Mf",
        "outputId": "3ae5a645-65da-448c-b1c8-cbf21ba1ca6d"
      },
      "source": [
        "#flatten images\n",
        "#print(train_loader.shape)\n",
        "# for image,label in enumerate(train_loader):\n",
        "#   print(images.shape)\n",
        "dataiter = iter (train_loader)\n",
        "images, labels = dataiter.next()\n",
        "print(images.shape)\n",
        "images = images.view(-1,784)\n",
        "print(images.shape)\n",
        "#train1 = train[0].view(-1,784)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 1, 28, 28])\n",
            "torch.Size([64, 784])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uqia0L2EmWX"
      },
      "source": [
        "def activation(x):\n",
        "  return 1/(1+torch.exp(-x))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2f6-1uvbFvD4"
      },
      "source": [
        "def softmax(x):\n",
        "  num = torch.exp(x)\n",
        "  den = torch.sum(torch.exp(x),1).view(-1,1)\n",
        "  return num/den"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEbVWLDHA0bp"
      },
      "source": [
        "h_vector = torch.mm(images,w1)+b1\n",
        "h_activated = activation(h_vector)\n",
        "y = softmax(torch.mm(h_activated,w2)+b2)\n",
        "print(y.shape)\n",
        "print(y)\n",
        "print(y.sum(dim=1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nn35OuCzVUw5"
      },
      "source": [
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "\n",
        "class Network(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.hidden1 = nn.Linear(784,128)\n",
        "    self.hidden2 = nn.Linear(128,64)\n",
        "    self.output = nn.Linear(64,10)\n",
        "\n",
        "  def forward (self,x):\n",
        "    x=F.relu(self.hidden1(x))\n",
        "    x=F.relu(self.hidden2(x))\n",
        "    x=F.log_softmax(self.output(x),dim=1)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mBa0Ij1YPng",
        "outputId": "151955f2-fbd4-473b-eaa6-2382d1cd6ab4"
      },
      "source": [
        "from tqdm import tqdm\n",
        "model = Network()\n",
        "print(model)\n",
        "#define loss\n",
        "criterion = nn.NLLLoss()\n",
        "#get optimizer\n",
        "optimizer = optim.SGD(model.parameters(),lr=0.01)\n",
        "epochs = 5\n",
        "for e in tqdm(range(epochs)):\n",
        "  running_loss=0\n",
        "  for images, labels in train_loader:\n",
        "    #flatten images\n",
        "    images = images.view(images.shape[0],-1)\n",
        "    optimizer.zero_grad() #clear gradient\n",
        "    #forward pass in the model\n",
        "    y = model(images)\n",
        "    loss = criterion(y, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    running_loss+=loss.item()\n",
        "\n",
        "  else:\n",
        "    print(f\"Training loss:{running_loss/len(train_loader)}\")\n",
        "\n"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/5 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Network(\n",
            "  (hidden1): Linear(in_features=784, out_features=128, bias=True)\n",
            "  (hidden2): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (output): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 1/5 [00:09<00:36,  9.21s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training loss:1.0673412506196545\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 2/5 [00:18<00:27,  9.23s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training loss:0.3886360198195809\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 3/5 [00:27<00:18,  9.18s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training loss:0.3262403793871276\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 4/5 [00:36<00:09,  9.19s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training loss:0.2944573290280696\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 5/5 [00:45<00:00,  9.16s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training loss:0.2707267450228302\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuYhBw7TpUO8"
      },
      "source": [
        "def imshow(image, ax=None, title=None, normalize=True):\n",
        "  \"\"\"Imshow for Tensor.\"\"\"\n",
        "  if ax is None:\n",
        "      fig, ax = plt.subplots()\n",
        "  image = image.numpy().transpose((1, 2, 0))\n",
        "\n",
        "  if normalize:\n",
        "      mean = np.array([0.485, 0.456, 0.406])\n",
        "      std = np.array([0.229, 0.224, 0.225])\n",
        "      image = std * image + mean\n",
        "      image = np.clip(image, 0, 1)\n",
        "\n",
        "  ax.imshow(image)\n",
        "  ax.spines['top'].set_visible(False)\n",
        "  ax.spines['right'].set_visible(False)\n",
        "  ax.spines['left'].set_visible(False)\n",
        "  ax.spines['bottom'].set_visible(False)\n",
        "  ax.tick_params(axis='both', length=0)\n",
        "  ax.set_xticklabels('')\n",
        "  ax.set_yticklabels('')\n",
        "\n",
        "  return ax"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "n8XgvfzRomRX",
        "outputId": "f5ab3753-53ea-4075-8dd3-718ab25b4aa3"
      },
      "source": [
        "%matplotlib inline\n",
        "import helper\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "images, labels = next(iter(train_loader))\n",
        "img = images[0].view(1,784)\n",
        "with torch.no_grad():\n",
        "  logits = model(img)\n",
        "\n",
        "ps = F.softmax(logits,dim=1)\n",
        "print(ps[0])\n",
        "imshow(img.view(1,28,28))\n",
        "torch.Tensor.ndim = property(lambda self: len(self.shape))  # Fix it\n",
        "\n",
        "plt.bar(ps[0],10)"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([5.1776e-06, 8.8238e-06, 1.4613e-04, 4.3556e-05, 9.9291e-01, 2.1959e-03,\n",
            "        1.0573e-03, 1.1020e-04, 7.1346e-04, 2.8108e-03])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 10 artists>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "width": 231,
              "height": 231
            },
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}